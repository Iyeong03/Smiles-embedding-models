{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프 임베딩 GNN"
      ],
      "metadata": {
        "id": "B0NitzcTG7dB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVcgXeqkG4Vq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.data import Data, DataLoader as GeometricDataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from rdkit import Chem\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Configuration and Initialization\n",
        "CFG = {\n",
        "    'BATCH_SIZE': 32,\n",
        "    'HIDDEN_DIM': 128,\n",
        "    'OUT_DIM': 1,\n",
        "    'LR': 0.001,\n",
        "    'EPOCHS': 100,\n",
        "    'SEED': 42,\n",
        "    'POOLING': 'mean'  # Change to 'max' or 'add' if desired\n",
        "}\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED'])  # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv, global_mean_pool\n",
        "\n",
        "class AtomEmbedding(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        super(AtomEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
        "\n",
        "    def forward(self, atom):\n",
        "        return self.embedding(atom)\n",
        "\n",
        "class BondEmbedding(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        super(BondEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
        "\n",
        "    def forward(self, bond):\n",
        "        return self.embedding(bond)"
      ],
      "metadata": {
        "id": "xnBuxsYTHH2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smiles_to_graph(smiles, atom_embedding, bond_embedding):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "\n",
        "    # Nodes (atoms)\n",
        "    atom_features = [atom_embedding(torch.tensor(atom.GetAtomicNum())) for atom in mol.GetAtoms()]\n",
        "    atom_features = torch.stack(atom_features)\n",
        "\n",
        "    # Edges (bonds)\n",
        "    edge_index = []\n",
        "    edge_attr = []\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        edge_index.append([i, j])\n",
        "        edge_index.append([j, i])\n",
        "\n",
        "        bond_type = bond.GetBondTypeAsDouble()\n",
        "        edge_attr.append(bond_embedding(torch.tensor(int(bond_type))))\n",
        "        edge_attr.append(bond_embedding(torch.tensor(int(bond_type))))\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.stack(edge_attr)\n",
        "\n",
        "    return Data(x=atom_features, edge_index=edge_index, edge_attr=edge_attr)"
      ],
      "metadata": {
        "id": "ZVmH4_07HI0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MoleculeDataset(Dataset):\n",
        "    def __init__(self, dataframe, atom_embedding, bond_embedding, is_train=True):\n",
        "        self.df = dataframe\n",
        "        self.atom_embedding = atom_embedding\n",
        "        self.bond_embedding = bond_embedding\n",
        "        self.graphs = [smiles_to_graph(smiles, atom_embedding, bond_embedding) for smiles in dataframe['Smiles']]\n",
        "        if is_train:\n",
        "            self.labels = torch.tensor(dataframe['pIC50'].values, dtype=torch.float32)\n",
        "        else:\n",
        "            self.labels = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph = self.graphs[idx]\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "            return graph, label\n",
        "        else:\n",
        "            return graph"
      ],
      "metadata": {
        "id": "1xlhtgpfHLAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, atom_embedding_dim, hidden_dim, out_dim):\n",
        "        super(GNNModel, self).__init__()\n",
        "        nn1 = nn.Sequential(nn.Linear(atom_embedding_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))\n",
        "        nn2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))\n",
        "        self.conv1 = GINConv(nn1)\n",
        "        self.conv2 = GINConv(nn2)\n",
        "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, data.batch)  # Global pooling\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "6gu9LCITHMQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to convert pIC50 to IC50\n",
        "def pIC50_to_IC50(pic50_values):\n",
        "    \"\"\"Convert pIC50 values to IC50 (nM).\"\"\"\n",
        "    return 10 ** (9 - pic50_values)\n"
      ],
      "metadata": {
        "id": "7qSnqFAmHOpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize embeddings\n",
        "atom_embedding_dim = 64\n",
        "bond_embedding_dim = 64\n",
        "\n",
        "# Define the number of unique atoms and bonds in your dataset\n",
        "num_atom_embeddings = 100  # Adjust based on your data\n",
        "num_bond_embeddings = 10  # Adjust based on your data\n",
        "\n",
        "atom_embedding = AtomEmbedding(num_embeddings=num_atom_embeddings, embedding_dim=atom_embedding_dim)\n",
        "bond_embedding = BondEmbedding(num_embeddings=num_bond_embeddings, embedding_dim=bond_embedding_dim)"
      ],
      "metadata": {
        "id": "FIbl9YiRHRFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/신약개발/train.csv')\n",
        "\n",
        "# Prepare training dataset and dataloader\n",
        "train_dataset = MoleculeDataset(train_data, atom_embedding, bond_embedding)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [int(len(train_dataset) * 0.7), len(train_dataset) - int(len(train_dataset) * 0.7)])\n",
        "\n",
        "train_loader = GeometricDataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
        "val_loader = GeometricDataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
      ],
      "metadata": {
        "id": "ZyUwBqZGHRgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, optimizer, and loss function\n",
        "model = GNNModel(atom_embedding_dim, hidden_dim=CFG['HIDDEN_DIM'], out_dim=CFG['OUT_DIM'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=CFG['LR'])\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(CFG['EPOCHS']):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data, labels in train_loader:\n",
        "        optimizer.zero_grad()  # 이전 그래프를 지우기 위해 초기화\n",
        "        preds = model(data)  # 모델 출력\n",
        "        preds = preds.squeeze()  # 필요 시 차원 조정\n",
        "        loss = criterion(preds, labels)\n",
        "        loss.backward(retain_graph=True)  # retain_graph=True로 설정하여 문제 해결 시도\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{CFG[\"EPOCHS\"]}], Loss: {avg_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "5j1wb8g8HTOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "model.eval()\n",
        "val_preds = []\n",
        "val_labels = []\n",
        "with torch.no_grad():\n",
        "    for data, labels in val_loader:\n",
        "        preds = model(data).squeeze()\n",
        "        val_preds.append(preds)\n",
        "        val_labels.append(labels)\n",
        "\n",
        "val_preds = torch.cat(val_preds).numpy()\n",
        "val_labels = torch.cat(val_labels).numpy()\n",
        "\n",
        "mse = mean_squared_error(pIC50_to_IC50(val_labels), pIC50_to_IC50(val_preds))\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Validation RMSE: {rmse}')"
      ],
      "metadata": {
        "id": "xn1jCgmeHVmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing and submission\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/신약개발/test.csv')\n",
        "test_dataset = MoleculeDataset(test_data, atom_embedding, bond_embedding, is_train=False)\n",
        "test_loader = GeometricDataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
        "\n",
        "test_preds = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        preds = model(data).squeeze()\n",
        "        test_preds.append(preds)\n",
        "\n",
        "test_preds = torch.cat(test_preds).numpy()"
      ],
      "metadata": {
        "id": "HGZYGLKnHW03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/신약개발/sample_submission.csv')\n",
        "submission['IC50_nM'] = pIC50_to_IC50(test_preds)\n",
        "submission.to_csv('/content/drive/MyDrive/신약개발/gcn_submit_graph.csv', index=False)"
      ],
      "metadata": {
        "id": "wS28BsDLHZiZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}